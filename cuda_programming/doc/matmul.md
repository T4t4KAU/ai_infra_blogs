# Building a High-Performance CUDA SGEMM Kernel: From Naive Implementation to Warp Tiling

æœ¬æ–‡è®²è§£å¦‚ä½•ä¸€æ­¥ä¸€æ­¥ç”¨CUDAå®ç°ä¸€ä¸ªé«˜æ€§èƒ½çš„SGEMMï¼ˆå•ç²¾åº¦çŸ©é˜µä¹˜æ³•ï¼‰ç®—å­ã€‚

å®éªŒç¯å¢ƒ:

| é…ç½® |             å‹å·             |
| :--: | :--------------------------: |
| CPU  | Intel(R) Core(TM) i5-14600KF |
|  OS  |         Ubuntu 24.04         |
| GPU  |       NVIDIA RTX 5070        |
| CUDA |             13.0             |

## V1 æœ€æœ´ç´ ç‰ˆçŸ©é˜µè¿ç®—

æºä»£ç ï¼š[matmul_v1.cu](https://github.com/T4t4KAU/ai_infra_blogs/blob/main/cuda_programming/src/matmul_v1.cu)

å·²çŸ¥çŸ©é˜µè¿ç®—å…¬å¼ï¼š
```math
C_{m,n}=\sum_{k=0}^{K-1}A_{m,k}\cdot B_{k,n}
```
ä»æ•°å­¦ä¸Šçœ‹ï¼ŒçŸ©é˜µè¿ç®—æ˜¯å¤©ç„¶å¯ä»¥å¹¶è¡Œçš„ï¼Œè¿™æ ·çš„è¿ç®—å¯ä»¥åˆ†è§£ï¼Œæ¯ä¸ªè¾“å‡ºå…ƒç´ éƒ½æ˜¯ä¸€ä¸ªç‹¬ç«‹ä»»åŠ¡ï¼Œæ±‚å’Œä¹ŸåŒæ ·å¯ä»¥å¹¶è¡Œï¼Œå¹¶ä¸”è¿™äº›å¹¶è¡Œçš„è®¡ç®—éƒ½è¾ƒä¸ºç®€å•ï¼Œæ— æ§åˆ¶é€»è¾‘ã€‚äºæ˜¯ï¼Œå¯ä»¥è½»æ˜“åœ°æƒ³åˆ°ï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨GPUçš„å¤§è§„æ¨¡å¹¶è¡Œè®¡ç®—èƒ½åŠ›æ¥é«˜æ ¡åœ°å®ŒæˆçŸ©é˜µè¿ç®—ã€‚

åœ¨å•ç²¾åº¦çŸ©é˜µä¹˜æ³•ä¸­ï¼Œå…¬å¼ä¸€èˆ¬å†™æˆï¼š
```math
C=\alpha\cdot A\cdot B+\beta\cdot C
```
äºæ˜¯ï¼Œå¯ä»¥å…ˆå†™å‡ºå¦‚ä¸‹ä»£ç ï¼š

```c++
__global__ void sgemm_kernel_v1(float *A, float *B, float *C, int M, int N, int K, float alpha, float beta) {
    int col = blockIdx.x * blockDim.x + threadIdx.x;
    int row = blockIdx.y * blockDim.y + threadIdx.y;

    if (row < M && col < N) {
        float sum_val = 0.;

        for (int k = 0; k < K; ++k) {
            sum_val += A[row * K + k] * B[k * N + col];
        }

        C[row * N + col] = alpha * sum_val + beta * C[row * N + col];
    }
}
```

æˆ‘ä»¬æƒ³è®©ä¸€ä¸ªcudaçº¿ç¨‹è´Ÿè´£è®¡ç®—Cä¸­çš„ä¸€ä¸ªå…ƒç´ ï¼Œè¿™æ ·è¦è®¡ç®—å‡ºMè¡ŒNåˆ—çš„çŸ©é˜µï¼Œè¦ç”¨åˆ°MÃ—Nä¸ªçº¿ç¨‹ã€‚

`__global__`å®šä¹‰äº†ä¸€ä¸ªGPU kernelå‡½æ•°ï¼Œè¡¨ç¤ºè¿™ä¸ªå‡½æ•°ç”±CPUå¯åŠ¨ï¼Œåœ¨GPUä¸Šç”±æ•°ä¸ªçº¿ç¨‹åŒæ—¶æ‰§è¡Œã€‚

è€ƒè™‘åˆ°çŸ©é˜µæ˜¯2Dæ•°æ®ç»“æ„ï¼Œå› æ­¤ç”¨2Dçº¿ç¨‹å—æ˜ å°„çŸ©é˜µæ•°æ®ã€‚`blockIdx.x`è¡¨ç¤ºçº¿ç¨‹å—åœ¨æ•´ä¸ªGPUç½‘æ ¼ä¸­çš„xæ–¹å‘ä¸Šçš„ç´¢å¼•ï¼Œ`blockDim.x`è¡¨ç¤ºçº¿ç¨‹å—åœ¨xæ–¹å‘çš„å¤§å°ï¼Œ`threadIdx.x`è¡¨ç¤ºåœ¨çº¿ç¨‹å—ä¸­çš„xæ–¹å‘ä¸Šå±äºç¬¬å‡ ä¸ªçº¿ç¨‹ã€‚

CUDAçš„çº¿ç¨‹åˆ†å±‚æ¨¡å‹å¯ä»¥å‚è§ï¼š[NVIDIA DOC | Thread Hierarchy](https://docs.nvidia.cn/cuda/cuda-c-programming-guide/index.html#thread-hierarchy)

ç”±æ­¤å¯çŸ¥ï¼Œä¸‹é¢ä¸¤è¡Œå…¶å®æ˜¯ç®—æ‰§è¡Œè¿™ä¸ªkernelçš„çº¿ç¨‹åœ¨å…¨å±€ç½‘æ ¼ä¸­çš„(x,y)åæ ‡ï¼Œä»¥æ­¤ç¡®å®šè¿™ä¸ªçº¿ç¨‹è¦è®¡ç®—çŸ©é˜µä¸­å“ªä¸€ä¸ªå…ƒç´ ï¼š

```c++
int col = blockIdx.x * blockDim.x + threadIdx.x; // è¦è®¡ç®—å…ƒç´ åœ¨çŸ©é˜µä¸­çš„åˆ—
int row = blockIdx.y * blockDim.y + threadIdx.y; // è¦è®¡ç®—å…ƒç´ åœ¨ä¸¾è¯ä¸­çš„è¡Œ
```

è¦æ³¨æ„çš„æ˜¯ï¼ŒGPUä¸Šçš„çº¿ç¨‹å—æ˜¯æ•´å—æ•´å—å¯åŠ¨çš„ï¼Œä¸ä¸€å®šèƒ½åˆšå¥½è¦†ç›–çŸ©é˜µï¼Œä¾‹å¦‚ä¸€ä¸ªçº¿ç¨‹å—æ˜¯16Ã—16ï¼Œä¸€ä¸ªçŸ©é˜µå¯ä»¥æ˜¯16Ã—18ï¼Œé‚£ä¹ˆè‡³å°‘å¾—ç”¨ä¸¤ä¸ªçº¿ç¨‹å—å®Œæˆè®¡ç®—ï¼Œäºæ˜¯ä¼šæœ‰ä¸€éƒ¨åˆ†çº¿ç¨‹è½åœ¨çŸ©é˜µè¾¹ç•Œå¤–ï¼Œå› æ­¤è¦æ³¨æ„è¶Šç•Œè®¿é—®ï¼š

```c++
if (row < M && col < N) { // æ£€æŸ¥æ˜¯å¦è¶Šç•Œ
	....
}
```

æ¥ä¸‹æ¥æŒ‰ç…§çŸ©é˜µè¿ç®—å…¬å¼å®ç°è®¡ç®—å³å¯ã€‚

ä¸éš¾å‘ç°ï¼Œè¿™æ ·çš„å®ç°åœ¨æ€§èƒ½ä¸Šå­˜åœ¨ä¸€äº›é—®é¢˜ï¼š

1. é¢‘ç¹è¯»å–å…¨å±€å†…å­˜ï¼Œæ‰€æœ‰çš„Aå’ŒBå…ƒç´ éƒ½æ˜¯ä»å…¨å±€å†…å­˜ä¸­è¯»å–ï¼Œè¿™æ ·æµªè´¹äº†å¤ªå¤šæ—¶é—´åœ¨è®¿å­˜ä¸Šï¼Œè®¡ç®—æ•ˆç‡ä½ä¸‹
2. è®¡ç®—å¼ºåº¦ä½ï¼Œä¹Ÿå°±æ˜¯ç®—çš„å°‘ï¼Œè¯»çš„å¤šï¼Œæ¯ä»æ˜¾å­˜æ¬ 8 ä¸ªå­—èŠ‚ï¼Œåªåšäº† 2 æ¬¡è®¡ç®—ï¼Œè®¡ç®—å•å…ƒè¢«å¤§é‡ç©ºé—²
3. ç¼ºä¹æ•°æ®å¤ç”¨ï¼Œæ¯ä¸ªçº¿ç¨‹éƒ½ä»å†…å­˜ä¸­è¯»å–Açš„ä¸€æ•´è¡Œï¼ŒBçš„ä¸€æ•´åˆ—ï¼Œè¿™ç±»æ•°æ®é‡å¤è¯»å–ï¼Œå±äºå†—ä½™æ“ä½œ

å¯ä»¥ç”¨NVIDIAæä¾›çš„[Nsight Compute](https://developer.nvidia.com/nsight-compute)æ¥åˆ†æï¼Œåœ¨å½“å‰ç›®å½•ä¸‹æ‰§è¡Œå‘½ä»¤ï¼Œä¼šåœ¨ç»ˆç«¯è¾“å‡ºå¤§é‡æ•°æ®ï¼š

```bash
nvcc -O3 matmul_v1.cu -o matmul # ç¼–è¯‘ä»£ç 
ncu ./matmul # è¦ç”¨rootæƒé™ï¼Œæ³¨æ„å½“å‰çš„ncuç‰ˆæœ¬èƒ½å¦ç”¨äºå½“å‰æ˜¾å¡
```

ä¹Ÿå¯ä»¥ä½¿ç”¨å°†æ•°æ®å¯è§†åŒ–ï¼Œå…ˆæ‰§è¡Œï¼š

```bash
ncu -o sgemm_v1 ./matmul #åœ¨ç›®å½•ä¸‹ä¼šç”Ÿæˆä¸€äº›æ–‡ä»¶
ncu-ui # ä¼šæ‰“å¼€ä¸€ä¸ªçª—å£
```

åœ¨å¼¹å‡ºçš„çª—å£ä¸­é€‰æ‹©"File"->"Open File"ç„¶åé€‰æ‹©ç”Ÿæˆçš„æ–‡ä»¶sgemm_v1.ncu-repï¼Œä¹‹åå°±å¯ä»¥çœ‹åˆ°åˆ†æç»“æœã€‚

å…³æ³¨ã€Section: GPU Speed Of Light Throughputã€ï¼Œå‘ç°L1 Cacheçš„è´Ÿè½½é«˜è¾¾90%ä»¥ä¸Šã€‚å¯çŸ¥L1 Cacheå‡ ä¹è¢«æ‰“æ»¡ï¼Œè¯´æ˜å¯¹å…¨å±€å†…å­˜çš„è®¿é—®å‹åŠ›ç¡®å®å¾ˆå¤§ï¼Œæ¥ä¸‹æ¥å°±ç€æ‰‹ä¼˜åŒ–è¿™ä¸€ç‚¹ã€‚

å¦‚ä¸‹æ˜¯æµ‹è¯•ç»“æœï¼š

![matmul_v1](https://github.com/T4t4KAU/ai_infra_blogs/blob/main/cuda_programming/img/matmul_1.png)

è¦è¡¥å……çš„æ˜¯ï¼Œåœ¨åšæ€§èƒ½æµ‹è¯•æ—¶åº”è¯¥æµ‹è¯•çš„æ˜¯kernelç¨³å®šè¿è¡Œæ—¶çš„æ€§èƒ½ï¼Œæ‰€ä»¥åº”è¯¥æ’é™¤ç¬¬ä¸€æ¬¡çš„å†·å¯åŠ¨ï¼Œè¯¦æƒ…è§å®é™…ä»£ç çš„æ³¨é‡Šã€‚

## V2 Thread Tileä¼˜åŒ–

æºä»£ç ï¼š[matmul_v2.cu](https://github.com/T4t4KAU/ai_infra_blogs/blob/main/cuda_programming/src/matmul_v2.cu)

åœ¨è¿™ä¸€ç‰ˆæœ¬ä»£ç ä¸­ï¼Œæˆ‘ä»¬è¦å¯¹åŸå§‹çš„ä»£ç è¿›è¡Œä¼˜åŒ–ï¼Œè§‚å¯Ÿåˆ°è®¿é—®å…¨å±€å†…å­˜è¿‡äºé¢‘ç¹ï¼Œå¾ˆå®¹æ˜“æƒ³åˆ°ç”¨å…±äº«å†…å­˜æ¥é¿å…é¢‘ç¹è®¿é—®å…¨å±€å†…å­˜ï¼ŒåŒæ—¶ä¹Ÿèƒ½å®ç°æ•°æ®å¤ç”¨ã€‚

åŒæ—¶ï¼Œåœ¨è®¡ç®—ä¸Šæˆ‘ä»¬è¦ç”¨åˆ†å—çŸ©é˜µä¹˜æ³•ï¼Œè®©ä¸€ä¸ªçº¿ç¨‹å—å»è®¡ç®—çŸ©é˜µCçš„ä¸€ä¸ªåˆ†å—ï¼ˆBMÃ—BNçŸ©é˜µï¼‰ï¼Œå¯ä½œå¦‚ä¸‹æ¨å¯¼ï¼š

æœ‰çŸ©é˜µCï¼š
```math
C=
\begin{bmatrix}
C_{0,0} & C_{0,1} & \cdots \\
C_{1,0} & C_{1,1} & \cdots \\
\vdots
\end{bmatrix}
```
è®¾çŸ©é˜µCçš„ä¸€ä¸ªåˆ†å—Blockçš„åæ ‡æ˜¯(p,q)ï¼Œåˆ™æœ‰ï¼š
```math
C^{(p,q)}\triangleq
\begin{array}
{c}C[pBM:(p+1)BM-1,\space
\end{array}qBN:(q+1)BN-1]
```


ä¸ä¹‹å¯¹åº”çš„ A Block ä¸ B Blockï¼š
```math
A^{(p)}\triangleq A[pBM:(p+1)BM-1,\mathrm{~}0:K-1] \\
B^{(q)}\triangleq B[0:K-1,qBN:(q+1)BN-1]
```
äºæ˜¯C Blockå¯ä»¥è¿™æ ·å¾—åˆ°ï¼š
```math
C^{(p,q)}=A^{(p)}\cdot B^{(q)}
```
å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![matmul_v2_1](https://github.com/T4t4KAU/ai_infra_blogs/blob/main/cuda_programming/img/matmul_3.png)

ä¸Šé¢çš„å¤§åˆ†å—ç§°ä¹‹ä¸º**Block**ï¼Œæ¥ä¸‹æ¥å°†KæŒ‰BKé•¿åº¦ä¹Ÿåšåˆ†å‰²ï¼Œå¾—åˆ°çš„å°åˆ†å—ç§°ä¸º**Tile**ï¼Œé‚£ä¹ˆå¯ä»¥å¦‚ä¸‹ç®—å‡ºå®Œæ•´çš„C Blockï¼š
```math
C_{block}=\sum_{t=0}^{K/BK-1}\left(A_{block}^{(t)}\cdot B_{block}^{(t)}\right)
```
å…¶ä¸­ï¼Œtæ ‡è¯†äº†è¿™ä¸ªTileåœ¨Blockä¸­çš„ç´¢å¼•ï¼š
```math
A_{block}^{(t)}\in\mathbb{R}^{BM\times BK} \\
B_{block}^{(t)}\in\mathbb{R}^{BK\times BN}
```
ä¸ä¹‹å¯¹åº”çš„A Tileå’ŒB Tileï¼š
```math
A^{(p,t)}\triangleq A[pBM:(p+1)BM-1,\mathrm{~}tBK:(t+1)BK-1] \\
B^{(q,t)}\triangleq B[tBK:(t+1)BK-1,\mathrm{~}qBN:(q+1)BN-1]
```
äºæ˜¯ï¼ŒC Blockçš„ç¬¬tä¸ªTileä¸­æ¯ä¸ªå…ƒç´ çš„è®¡ç®—å¦‚ä¸‹ï¼š
```math
\boxed{C^{(p,q,t)}\triangleq A^{(p,t)}\cdot B^{(q,t)}}\quad\Rightarrow\quad C^{(p,q,t)}\in\mathbb{R}^{BM\times BN}
```
å°†æ‰€æœ‰C Tileæ±‚å’Œï¼Œå¾—åˆ°æœ€åçš„å®Œæ•´C Blockï¼š
```math
C^{(p,q)}=\sum_{t=0}^{T-1}C^{(p,q,t)}=\sum_{t=0}^{T-1}A^{(p,t)}\cdot B^{(q,t)}
```
å¯é€šè¿‡ä¸‹å›¾ç†è§£ï¼š

![matmul_v2_2](https://github.com/T4t4KAU/ai_infra_blogs/blob/main/cuda_programming/img/matmul_4.png)

ä¸Šé¢æåˆ°ï¼Œè¦ç”¨ä¸€ä¸ªçº¿ç¨‹å—è®¡ç®—ä¸€ä¸ªBlockï¼Œé‚£ä¹ˆå¦‚ä½•å°†ä¸€ä¸ªBlockåˆ†é…ç»™çº¿ç¨‹å—ä¸­çš„å¤šä¸ªçº¿ç¨‹ï¼Ÿ

å…ˆå®šä¹‰çº¿ç¨‹çš„é€»è¾‘åæ ‡æ˜¯(u, v)ï¼Œå¹¶è®©ä¸€ä¸ªçº¿ç¨‹è®¡ç®—å‡ºä¸€ä¸ªTMÃ—TNåˆ†å—ï¼Œåˆ™åæ ‡æ»¡è¶³ï¼š
```math
\begin{aligned}
u & =0,1,\ldots,\frac{BM}{TM}-1 \\
v & =0,1,\ldots,\frac{BN}{TN}-1
\end{aligned}
```
äºæ˜¯ä¸€ä¸ªçº¿ç¨‹è´Ÿè´£ç®—å‡ºå¦‚ä¸‹å°åˆ†å—ï¼š
```math
C_{u,v}^{(p,q)}\triangleq C^{(p,q)}[uTM:(u+1)TM-1,\mathrm{~}vTN:(v+1)TN-1]
```
ä¹Ÿå°±æ˜¯ï¼š

![matmul_v2_3](https://github.com/T4t4KAU/ai_infra_blogs/blob/main/cuda_programming/img/matmul_5.png)

å¦‚ä¸Šæ‰€ç¤ºï¼Œæˆ‘ä»¬å°†ä¸€ä¸ªçŸ©é˜µè¿ç®—åˆ’åˆ†æˆäº†ä¸‰å±‚ç»“æ„ï¼Œå…ˆå¯¹Mè¡ŒNåˆ—åˆ’åˆ†ï¼Œå°†Cåˆ’åˆ†å‡ºBMÃ—BNçš„C Blockï¼Œå°†Aåˆ’åˆ†æˆBMÃ—Kçš„A Blockï¼Œå°†Båˆ’åˆ†æˆKÃ—BNçš„B Blockï¼›æ¥ç€å¯¹Kè¿›è¡Œåˆ’åˆ†ï¼ŒA Blockåˆ’åˆ†æˆBMÃ—BKçš„A Tileï¼ŒB Blockåˆ’åˆ†å‡ºBMÃ—BKçš„B Tileï¼›æœ€åè€ƒè™‘çº¿ç¨‹åˆ†é…ï¼Œå°†Blockåˆ’åˆ†å‡ºTMÃ—TNçš„å—ï¼Œç”±ä¸€ä¸ªçº¿ç¨‹è´Ÿè´£è¿ç®—ã€‚

**è¿™æ ·åˆ’åˆ†æœ‰ä»€ä¹ˆå¥½å¤„ï¼Ÿ**

ç¬¬ä¸€æ­¥åˆ’åˆ†æ˜¯ä¸ºäº†è®©ä¸€ä¸ªçº¿ç¨‹å—è®¡ç®—ä¸€ä¸ªC Blockï¼Œä¸€ä¸ªçº¿ç¨‹å—å†…çš„çº¿ç¨‹å¯ä»¥å…±äº«æ•°æ®ï¼Œè¿™æ ·å°±å®ç°äº†æ•°æ®å¤ç”¨ã€‚å¯ä»¥å°†è¦ç”¨çš„çŸ©é˜µå—å…ˆè¯»åˆ°å…±äº«å†…å­˜ä¸­ï¼Œåœ¨çº¿ç¨‹å—ä¸­å…±äº«ï¼Œè¿™æ ·Açš„ä¸€è¡Œå¯ä»¥è¢«BNä¸ªåˆ—é‡å¤ä½¿ç”¨ï¼ŒBçš„ä¸€åˆ—å¯ä»¥è¢«BMä¸ªè¡Œé‡å¤ä½¿ç”¨ï¼Œå°±ä¸åƒV1ç‰ˆæœ¬çš„ä»£ç ï¼Œæ¯ä¸ªçº¿ç¨‹åšä¸€æ¬¡è¿ç®—éƒ½è¦è¯»å–ä¸€æ•´è¡Œï¼Œä¸€æ•´åˆ—ï¼Œå®Œå…¨æ²¡ç”¨åˆ°çº¿ç¨‹å—çš„æ•°æ®å¤ç”¨ç‰¹æ€§ã€‚ä¸è¿‡è¿™ä¸ªBMå’ŒBNçš„å¤§å°è¦è€ƒè™‘åˆ°å…±äº«å†…å­˜çš„å®¹é‡è¿›è¡Œè®¾ç½®ã€‚

ç¬¬äºŒæ­¥åˆ’åˆ†æ˜¯è€ƒè™‘åˆ°å…±äº«å†…å­˜å®¹é‡æœ‰é™ï¼ŒKå¯èƒ½ä¼šå¾ˆå¤§ï¼Œå…±äº«å†…å­˜ä¸­æ ¹æœ¬æ”¾ä¸ä¸‹ï¼Œæ‰€ä»¥å¾—å°†Kåˆ†å‰²ã€‚

ç¬¬ä¸‰æ­¥åˆ’åˆ†æ˜¯è€ƒè™‘åˆ°æŒ‡ä»¤å¹¶è¡Œï¼Œå†³å®šä¸€ä¸ªçº¿ç¨‹ç®—å“ªäº›å…ƒç´ ï¼Œè¿™æ ·ä¹Ÿèƒ½åˆ©ç”¨å¥½çº¿ç¨‹è‡ªèº«çš„å¯„å­˜å™¨ã€‚

æ¥ä¸‹æ¥æ¼”ç¤ºä»£ç å¦‚ä½•ç¼–å†™ã€‚

é¦–å…ˆæ˜¯ç¡®å®šå½“å‰çº¿ç¨‹å—åº”è¯¥è®¡ç®—C Blockçš„å“ªä¸€éƒ¨åˆ†ï¼š

```c
/* ------------------------------
* Block coordinates
* Each block computes one BMÃ—BN tile of C
* ------------------------------ */     
const int block_col = blockIdx.x; // index in N dimension
const int block_row = blockIdx.y; // index in M dimension
```

è¿™ä¸ªç”±Thread Blockçš„åæ ‡å†³å®šå³å¯ã€‚

æ¥ä¸‹æ¥ç¡®å®šè¦ç”¨åˆ°çš„çº¿ç¨‹æ•°ï¼š

```c
/* ------------------------------
* Thread layout inside a block
* Threads are logically arranged in 2D:
*   (BM / TM) Ã— (BN / TN)
* ------------------------------ */
const int threads_per_row = BN / TN;
const int threads_per_col = BM / TM;
const int num_threads = threads_per_row * threads_per_col;
```

ç¡®å®šå½“å‰çº¿ç¨‹è¦ç®—C Blockä¸­çš„å“ªä¸€éƒ¨åˆ†ï¼ˆè®¡ç®—å…·ä½“ä½ç½®ï¼‰ï¼š

```c
/* ------------------------------
* Per-thread output tile offset
* Each thread computes a TMÃ—TN sub-tile of C
* ------------------------------ */
const int tx = (threadIdx.x % threads_per_row) * TN; // column offset
const int ty = (threadIdx.x / threads_per_row) * TM; // row offset
```

åˆ›å»ºå…±äº«å†…å­˜ï¼š

```c
/* ------------------------------
* Shared memory for A and B tiles
* As : BM Ã— BK
* Bs : BK Ã— BN
* ------------------------------ */
__shared__ float As[BM * BK];
__shared__ float Bs[BK * BN];
```

æ‹¿åˆ°è¦ç”¨çš„A Blockå’ŒB Blockå¹¶å°†æŒ‡é’ˆæ”¾åˆ°çŸ©é˜µCçš„å¯¹åº”ä½ç½®ä¸Šï¼š

```c
/* ------------------------------
* Move global pointers to the
* beginning of the current block tile
* ------------------------------ */    
float *A_block = A + block_row * BM * K;
float *B_block = B + block_col * BN;
float *C_block = C + block_row * BM * N + block_col * BN;
```

æ¥ä¸‹æ¥è¦ä»å…¨å±€å†…å­˜åŠ è½½è¦ç”¨çš„æ•°æ®åˆ°å…±äº«å†…å­˜ï¼š

```c
/* ------------------------------
* Thread mapping for loading A tile
* ------------------------------ */
const int a_tile_row = threadIdx.x / BK;
const int a_tile_col = threadIdx.x % BK;
const int a_tile_stride = num_threads / BK;

const int b_tile_row = threadIdx.x / BN;
const int b_tile_col = threadIdx.x % BN;
const int b_tile_stride = num_threads / BN;

#pragma unroll
for (int k = 0; k < K; k += BK) {
/* ------------------------------
 * Load A tile into shared memory
 * ------------------------------ */
#pragma unroll
    for (int i = 0; i < BM; i += a_tile_stride) {
        As[(a_tile_row + i) * BK + a_tile_col] = A_block[(a_tile_row + i) * K + a_tile_col];
    }
/* ------------------------------
 * Load B tile into shared memory
 * ------------------------------ */
#pragma unroll
    for (int i = 0; i < BK; i += b_tile_stride) {
        Bs[(b_tile_row + i) * BN + b_tile_col] = B_block[(b_tile_row + i) * N + b_tile_col];
    }

    __syncthreads(); // Ensure As and Bs are fully loaded


    /* ------------------------------
     * Advance A and B pointers
     * ------------------------------ */
    A_block += BK;
    B_block += BK * N;
}
```

æ¯ä¸€è½®åŠ è½½ä¸€ä¸ªA Tileå’Œä¸€ä¸ªB Tileåˆ°å…±äº«å†…å­˜ï¼Œé‚£ä¹ˆä¸€å…±å°±æœ‰(K/BK)è½®ï¼Œæ¯ä¸ªçº¿ç¨‹è´Ÿè´£æ¬è¿ä¸€éƒ¨åˆ†æ•°æ®ï¼ŒA Tileä¸­çš„æ˜ å°„å…³ç³»å¤§è‡´å¦‚ä¸‹ï¼š

```
thread 0: A_block(0, 0) â†’ As(0, 0), A_block(0 + stride, 0) â†’ As(0 + stride, 0), ...
thread 1: A_block(0, 1) â†’ As(0, 1), A_block(0 + stride, 1) â†’ As(0 + stride, 1), ...
thread 2: A_block(0, 2) â†’ As(0, 2), A_block(0 + stride, 2) â†’ As(0 + stride, 2), ...
...
thread X: A_block(0, X) â†’ As(0, X), A_block(0 + stride, X) â†’ As(0 + stride, X)
...
thread BK: A_block(1, 0) â†’ As(1, 0), A_block(1 + stride, 0) â†’ As(1 + stride, 0), ...
thread (BK + 1): A_block(1, 1) â†’ As(1, 1), A_block(1 + stride, 1) â†’ As(1 + stride, 1), ...
...
```

æœ€åè¦ç”¨`__syncthreads()`è¿›è¡ŒåŒæ­¥ï¼Œç¡®ä¿æ‰€æœ‰çº¿ç¨‹éƒ½å®Œæˆã€‚åŠ è½½å®Œä¸€ä¸ªTileåè¦æŠŠæŒ‡é’ˆå‘å‰ç§»åŠ¨ï¼Œä¾¿äºä¸‹ä¸€è½®åŠ è½½åç»­çš„Tileåˆ°å…±äº«å†…å­˜ã€‚

åœ¨æ¯ä¸€è½®åŠ è½½Tileæ•°æ®çš„åŒæ—¶ï¼Œä¹Ÿè¦å®Œæˆè®¡ç®—ï¼š

```c
#pragma unroll
    for (int k = 0; k < K; k += BK) {
    /* ------------------------------
     * Load A tile into shared memory
     * ------------------------------ */
#pragma unroll
        for (int i = 0; i < BM; i += a_tile_stride) {
            As[(a_tile_row + i) * BK + a_tile_col] = A_block[(a_tile_row + i) * K + a_tile_col];
        }
    /* ------------------------------
     * Load B tile into shared memory
     * ------------------------------ */
#pragma unroll
        for (int i = 0; i < BK; i += b_tile_stride) {
            Bs[(b_tile_row + i) * BN + b_tile_col] = B_block[(b_tile_row + i) * N + b_tile_col];
        }

        __syncthreads(); // Ensure As and Bs are fully loaded


        /* ------------------------------
            * Advance A and B pointers
            * ------------------------------ */
        A_block += BK;
        B_block += BK * N;

        /* ------------------------------
        * Compute: register-level GEMM
        * ------------------------------ */
#pragma unroll
        for (int t = 0; t < BK; ++t) {
#pragma unroll
            for (int i = 0; i < TM; ++i) {
                for (int j = 0; j < TN; ++j) {
                    accum[i][j] += As[(ty + i) * BK + t] * Bs[t * BN + (tx + j)];
                }
            }
        }
        __syncthreads();
    }
```

å¯ä»¥çœ‹åˆ°ç°åœ¨è·å–æ•°æ®ç›´æ¥ä»å…±äº«å†…å­˜ä¸­è·å¾—å³å¯ï¼Œä¸€ä¸ªçº¿ç¨‹è®¡ç®—å‡ºæ¯ä¸ªK-Tileä¸­TMÃ—TNçš„åˆ†å—ï¼Œå†å°†æ‰€æœ‰K-Tileçš„ç»“æœåŠ å’Œï¼Œå¾—åˆ°è¿™ä¸€è½®æœ€ç»ˆè¿ç®—ç»“æœï¼Œå³ä¸€ä¸ªC Blockä¸­TMÃ—TNåˆ†å—çš„æœ€ç»ˆç»“æœã€‚

æœ€åä¸€æ­¥å°†TMÃ—TNåˆ†å—çš„ç»“æœä»£å…¥å¹¶å†™å›åˆ°C Blockå³å¯ï¼š

```c
#pragma unroll
    for (int i = 0; i < TM; ++i) {
        for (int j = 0; j < TN; ++j) {
            // C_block(ty + i, tx + j) = alpha Ã— accum(i, j) + beta Ã— C_block(ty + i, tx + j)
            C_block[(ty + i) * N + (tx + j)] = alpha * accum[i][j] + beta * C_block[(ty + i) * N + (tx + j)];
        }
    }
```

åœ¨ä¸Šè¿°æ‰€æœ‰ä»£ç ä¸­ï¼Œç´¢å¼•è®¡ç®—æ˜¯ä¸€ä¸ªéš¾ç‚¹ï¼Œå¿…é¡»å¾—è°¨æ…å¤„ç†ã€‚

ä¸‹é¢çœ‹çœ‹Nsight Computeçš„åˆ†æç»“æœï¼š

![matmul_v2](https://github.com/T4t4KAU/ai_infra_blogs/blob/main/cuda_programming/img/matmul_2.png)

å¯ä»¥å‘ç°æ¶ˆè€—çš„æ—¶é—´å’Œç¼“å­˜çš„è´Ÿè½½éƒ½å¤§å¤§å‡å°‘ï¼Œè®¡ç®—å¯†åº¦å’ŒæŒ‡ä»¤å¹¶è¡Œéƒ½å¾—åˆ°äº†æé«˜ã€‚

ä½†æ˜¯å¯ä»¥å‘ç°V1çš„æµ‹è¯•ç»“æœä¸­çš„ç®—åŠ›ç†è®ºå³°å€¼ï¼ˆCompute (SM) Throughput %ï¼‰æ¯”V2é«˜å¾—å¤šï¼Œä¸è¿‡è¿™ä¸ä»£è¡¨V1ç®—çš„æ›´å¿«æˆ–åˆ©ç”¨ç‡æ›´é«˜ï¼Œå› ä¸ºè¿™ä¸ªæŒ‡æ ‡å®é™…ä¸Šæ˜¯ã€è®¡ç®—æŒ‡ä»¤å‘å°„ç‡/ç†è®ºæœ€å¤§å‘å°„ç‡ã€ï¼Œè¿™ä¸ªæŒ‡æ ‡åªåæ˜ "å¿™ä¸å¿™"ï¼Œè€Œä¸åæ˜ "å¹²äº†å¤šå°‘"ã€‚V1ä¸­æ¯ä¸ªçº¿ç¨‹åªåšäº†å¾ˆç®€å•çš„è¿ç®—ï¼Œæ•…è€ŒæŒ‡ä»¤å‘å°„æ¯”ä¾‹éå¸¸é«˜ï¼Œä½†å®é™…ä¸Šæ¯ä¸ªçº¿ç¨‹å¹²çš„å¾ˆå°‘ï¼›V2ä¸­çš„æŒ‡ä»¤æ›´å¤æ‚ï¼Œç”¨åˆ°äº†å¯¹å…±äº«å†…å­˜çš„load/storeä»¥åŠåŒæ­¥æŒ‡ä»¤ï¼Œä¸æ˜¯æ¯ä¸ªå‘¨æœŸéƒ½åœ¨è¿è¡Œè®¡ç®—æŒ‡ä»¤ï¼Œæ‰€ä»¥æŒ‡ä»¤å‘å°„ç‡é™ä½ï¼Œå› æ­¤è¿™ä¸ªæŒ‡æ ‡å®é™…ä¸Šä¸ä½“ç°è®¡ç®—é€Ÿåº¦ã€‚

## V3 å‘é‡åŒ–é¢„å–

æºä»£ç ï¼š[matmul_v3.cu](https://github.com/T4t4KAU/ai_infra_blogs/blob/main/cuda_programming/src/matmul_v3.cu)

ä¸€ä¸ªwarpçš„32ä¸ªçº¿ç¨‹è®¿é—®å…¨å±€å†…å­˜æ—¶ï¼Œå¦‚æœåœ°å€è¿ç»­ã€å¯¹é½åˆ™GPUå¯ä»¥ç”¨æœ€å°‘çš„å†…å­˜äº‹åŠ¡å®Œæˆè®¿é—®ï¼Œå³åˆå¹¶è®¿å­˜ã€‚

å¦‚ä¸‹æ˜¯32ä¸ªçº¿ç¨‹è®¿é—®è¿ç»­çš„ã€å¯¹é½çš„åœ°å€ï¼Œä¸”ä½¿ç”¨çš„æ•°æ®ç±»å‹å®Œå…¨ç›¸åŒï¼š

```
thread 0 â†’ addr + 0
thread 1 â†’ addr + 1
thread 2 â†’ addr + 2
...
thread 31 â†’ addr + 31
```

åªéœ€è¦1ï½2æ¬¡å†…å­˜äº‹åŠ¡å°±å¯ä»¥å®Œæˆè¯¥è®¿é—®ï¼Œå¸¦å®½åˆ©ç”¨ç‡æ¥è¿‘100%ã€‚

ä½†å¦‚æœæ˜¯è·¨åº¦è¾ƒå¤§ä¸”ä¸è¿ç»­çš„å†…å­˜è®¿é—®ï¼š

```
thread 0 â†’ addr + 0
thread 1 â†’ addr + 64
thread 2 â†’ addr + 128
...
```

è¿™ä¸å¾—ä¸éœ€è¦32æ¬¡å†…å­˜äº‹åŠ¡ã€‚

å‘é‡åŒ–è®¿å­˜å¯ä»¥è®©ä¸€ä¸ªçº¿ç¨‹ç”¨ä¸€æ¬¡æŒ‡ä»¤åŠ è½½å¤šä¸ªè¿ç»­å…ƒç´ ï¼ˆå¦‚ 4Ã—floatï¼‰ï¼Œ ä»¥æ›´é«˜çš„å†…å­˜å¸¦å®½æ•ˆç‡ã€æ›´å°‘çš„æŒ‡ä»¤æ•°æŠŠæ•°æ®æ¬è¿›æ¥ï¼Œè¿™æ ·å°±å¯ä»¥å‡å°‘æŒ‡ä»¤æ•°é‡è¿˜èƒ½åˆ©ç”¨å†…å­˜äº‹åŠ¡ã€‚

å…ˆå®šä¹‰ä¸¤ä¸ªå®ï¼š

```c
// Row-major linear index
#define OFFSET(row, col, ld) ((row) * (ld) + (col))

// Vectorized float4 load/store helper
#define FETCH_FLOAT4(ptr) (reinterpret_cast<float4 *>(&(ptr))[0])
```

`OFFSET`æ˜¯è®¡ç®—è¡Œä¸»åºçŸ©é˜µçš„åç§»ï¼Œ`FETCH_FLOAT4`æŒ‰ä¸€ä¸ª `float4` æ•´ä½“ï¼Œæ‹·è´åˆ° `ldg_a_reg[reg_idx ... reg_idx+3]`ï¼Œé€šå¸¸ä¼šç”Ÿæˆ 1 æ¡ 128-bit load æŒ‡ä»¤ï¼Œä½¿ç”¨æ›´å®½çš„loadæŒ‡ä»¤å¯ä»¥å‡å°‘æ•°æ®æ¬è¿æ¬¡æ•°ã€‚

å¦‚ä¸‹æ˜¯ä¸¤æ®µç­‰ä»·çš„ä»£ç ï¼š

```c
// ä¸€æ¬¡å–ä¸€ä¸ªFLOAT4
FETCH_FLOAT4(ldg_a_reg[reg_idx]) = FETCH_FLOAT4(A_block[OFFSET(a_tile_row + i, a_tile_col, K)]);

// ç­‰ä»·äºä¸€æ¬¡æ‰§è¡Œå¦‚ä¸‹ä»£ç 
ldg_a_reg[reg_idx + 0] = A_block[(a_tile_row + i) * K + (a_tile_col + 0)];
ldg_a_reg[reg_idx + 1] = A_block[(a_tile_row + i) * K + (a_tile_col + 1)];
ldg_a_reg[reg_idx + 2] = A_block[(a_tile_row + i) * K + (a_tile_col + 2)];
ldg_a_reg[reg_idx + 3] = A_block[(a_tile_row + i) * K + (a_tile_col + 3)];
```

äºæ˜¯ï¼Œè¿™ä¸€ç‰ˆçš„ä»£ç å¯¹äºä¸Šä¸€ç‰ˆæœ¬çš„ä¼˜åŒ–ä¸»è¦ä½“ç°åœ¨ä½¿ç”¨æ›´å®½çš„loadæŒ‡ä»¤è®¿é—®å†…å­˜ï¼Œæ¯ä¸ªçº¿ç¨‹åœ¨åŒæ ·çš„æ—¶é—´å¼€é”€ä¸‹å¯ä»¥æ¬è¿æ›´å¤šçš„æ•°æ®ï¼Œå¯ä»¥è¿›ä¸€æ­¥æå‡æ€§èƒ½ã€‚

ç›´æ¥åœ¨ä¸Šä¸€ç‰ˆä»£ç çš„åŸºç¡€ä¸Šä¿®æ”¹ä»£ç ï¼š

```c
// æ¯ä¸ªçº¿ç¨‹è¦æ¬è¿å¤šå°‘æ¬¡
const int ldg_a_num = BK * BM / num_threads / 4; // ä»Aä¸­æ¬è¿çš„æ¬¡æ•°
const int ldg_b_num = BK * BN / num_threads / 4; // ä»Bä¸­æ¬è¿çš„æ¬¡æ•°
```

å› ä¸ºç°åœ¨æ•°æ®å®½åº¦å˜ä¸º4å€ï¼Œæ‰€ä»¥ä¸‹é¢çš„ç´¢å¼•è¦é‡æ–°è®¡ç®—ï¼š

```c
/* ------------------------------
 * Thread mapping for loading A tile
 * ------------------------------ */
const int a_tile_row = threadIdx.x / (BK / 4);
const int a_tile_col = (threadIdx.x % (BK / 4)) * 4;
const int a_tile_stride = BM / ldg_a_num;
const int b_tile_row = threadIdx.x / (BN / 4);
const int b_tile_col = (threadIdx.x % (BN / 4)) * 4;
const int b_tile_stride = BK / ldg_b_num;
```

æ•°æ®åŠ è½½å¦‚ä¸‹ï¼Œå¯ä»¥çœ‹åˆ°æˆ‘ä»¬ç”¨`FETCH_FLOAT4`è¿›è¡Œè¯»å–ï¼Œè¿™æ ·ä¸€æ¬¡loadå¯ä»¥è¯»åˆ°4ä¸ªfloatå®½åº¦çš„æ•°æ®ã€‚

```c
#pragma unroll
    for (int k = 0; k < K; k += BK) {
        /* ------------------------------
         * Load A tile into shared memory
         * ------------------------------ */
#pragma unroll
        for (int i = 0; i < BM; i += a_tile_stride) {
            int reg_idx = (i / a_tile_stride) * 4;

            // load float4 from global A
            // è¿™é‡Œä½¿ç”¨äº†å¯„å­˜å™¨è¿›è¡Œè¿‡æ¸¡
            FETCH_FLOAT4(ldg_a_reg[reg_idx]) = FETCH_FLOAT4(A_block[OFFSET(a_tile_row + i, a_tile_col, K)]);

            // store into shared As as transposed
            As[OFFSET(a_tile_col + 0, a_tile_row + i, BM)] = ldg_a_reg[reg_idx + 0];
            As[OFFSET(a_tile_col + 1, a_tile_row + i, BM)] = ldg_a_reg[reg_idx + 1];
            As[OFFSET(a_tile_col + 2, a_tile_row + i, BM)] = ldg_a_reg[reg_idx + 2];
            As[OFFSET(a_tile_col + 3, a_tile_row + i, BM)] = ldg_a_reg[reg_idx + 3];
        }

        /* ------------------------------
         * Load B tile into shared memory
         * ------------------------------ */
#pragma unroll
        for (int i = 0; i < BK; i += b_tile_stride) {
            FETCH_FLOAT4(Bs[OFFSET(b_tile_row + i, b_tile_col, BN)])
                = FETCH_FLOAT4(B_block[OFFSET(b_tile_row + i, b_tile_col, N)]);
        }

        __syncthreads(); // Ensure As and Bs are fully loaded

        // Advance global pointers
        A_block += BK;
        B_block += BK * N;

		....
    }
```

è¦æ³¨æ„çš„æ˜¯ï¼Œè¿™é‡Œçš„Aæ˜¯è½¬ç½®åå­˜åˆ°å…±äº«å†…å­˜ä¸­ï¼Œä¸ºä»€ä¹ˆè¦è¿™æ ·åšå‘¢ï¼Ÿ

è¿™ä¸å¾—ä¸è”ç³»åˆ°GPUå…±äº«å†…å­˜æœ¬èº«çš„ç‰¹æ€§ï¼Œå…±äº«å†…å­˜è¢«åˆ’åˆ†æˆ32ä¸ªBankï¼Œæ¯ä¸ªBankæœ‰4Bçš„å®¹é‡ï¼Œå½“æœ‰**å¤šä¸ªçº¿ç¨‹åŒæ—¶è®¿é—®ä¸€ä¸ªBankçš„ä¸åŒåœ°å€**æ—¶ï¼Œå°±ä¼šå‡ºç°Bank Conflictï¼Œé‚£ä¹ˆè¿™äº›è®¿é—®è¯·æ±‚ä¼šè¢«æ‹†åˆ†ä¸ºé¡ºåºè¯·æ±‚ï¼ˆä¸€æ¬¡è®¿é—®è¢«æ‹†æˆå¤šæ¬¡ï¼‰ï¼Œè‡ªç„¶è¦æ›´å¤šçš„æ—¶é—´ï¼›åç›´è§‰çš„æ˜¯ï¼Œå¤šä¸ªçº¿ç¨‹åŒæ—¶è®¿é—®ä¸€ä¸ªBankçš„ç›¸åŒåœ°å€å¹¶ä¸ä¼šå‡ºç°Conflictï¼Œæ­¤æ—¶ä¼šè§¦å‘å¹¿æ’­æœºåˆ¶ï¼Œè®¿é—®è¯·æ±‚ä¸ä¼šè¢«æ‹†åˆ†æˆé¡ºåºè¯·æ±‚ã€‚

æ›´å…·ä½“çš„æ˜¯ï¼Œå¯¹äºä¸¤ä¸ªçº¿ç¨‹åˆ†åˆ«è®¿é—®åœ°å€Xå’Œåœ°å€Yï¼Œä¸”Xä¸ç­‰äºYï¼Œä½†(x / 4) mod 32 ç­‰äº (Y / 4) mod 32é‚£ä¹ˆå°±ä¼šå‡ºç°Conflictï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œä¸‰ç§è®¿é—®æƒ…å†µéƒ½æ²¡æœ‰Conflictï¼Œå³ä½¿ä¸­é—´çš„5å·Bankçš„ä¸€ä¸ªåœ°å€è¢«å¤šä¸ªçº¿ç¨‹è®¿é—®ä¹Ÿæ²¡å‡ºç°Conflictï¼Œå› ä¸ºå­˜åœ¨å¹¿æ’­æœºåˆ¶ã€‚

![Irregular Shared Memory Accesses.](https://docs.nvidia.com/cuda/cuda-c-programming-guide/_images/examples-of-irregular-shared-memory-accesses.png)

ä½†æ˜¯ä¸‹é¢è¿™å¼ å›¾çš„ä¸­é—´éƒ¨åˆ†æ˜¯å­˜åœ¨Conflictçš„ï¼Œå› ä¸ºä¸€ä¸ªBankä¸­çš„ä¸åŒåœ°å€è¢«å¤šä¸ªçº¿ç¨‹è®¿é—®ã€‚

![Strided Shared Memory Accesses in 32 bit bank size mode.](https://docs.nvidia.com/cuda/cuda-c-programming-guide/_images/examples-of-strided-shared-memory-accesses.png)

æ›´å¤šä¿¡æ¯å¯ä»¥å‚è€ƒï¼š[NVIDIA DOC | Shared Memory](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html?highlight=bank#shared-memory-5-x)

å›é¡¾V2çš„è®¿é—®æ–¹å¼ï¼š

```c
#pragma unroll
    for (int t = 0; t < BK; ++t) {
#pragma unroll
        for (int i = 0; i < TM; ++i) {
            for (int j = 0; j < TN; ++j) { accum[i][j] += As[(ty + i) * BK + t] * Bs[t * BN + (tx + j)]; }
        }
    }
```

å¦‚æœä¸€ä¸ªwarpå†…çš„çº¿ç¨‹çš„ `((ty + i) * BK + t) mod 32`æ˜¯ä¸€æ ·çš„ï¼Œåˆ™å‘ç”ŸBank Conflictï¼Œé‚£ä¹ˆè¿™å°±å½±å“äº†æ‰§è¡Œé€Ÿåº¦ï¼Œè½¬ç½®æ˜¯ä¸ºäº†é¿å…è¿™ç§é—®é¢˜ã€‚

æˆ‘ä»¬å†™å‡ºæœ€åçš„è®¡ç®—è¿‡ç¨‹ï¼š

```c
/* ------------------------------
 * Compute: register-level GEMM
 * ------------------------------ */
#pragma unroll
for (int t = 0; t < BK; ++t) {
#pragma unroll
    for (int m = 0; m < TM; m += 4) { FETCH_FLOAT4(a_frag[m]) = FETCH_FLOAT4(As[OFFSET(t, ty + m, BM)]); }
#pragma unroll
    for (int n = 0; n < TN; n += 4) { FETCH_FLOAT4(b_frag[n]) = FETCH_FLOAT4(Bs[OFFSET(t, tx + n, BN)]); }
#pragma unroll
    for (int i = 0; i < TM; ++i) {
#pragma unroll
        for (int j = 0; j < TN; ++j) { accum[i][j] += a_frag[i] * b_frag[j]; }
    }
}
```

æœ€åå†™å›åˆ°C Blockï¼š

```c
// Write back C
#pragma unroll
for (int m = 0; m < TM; ++m) {
#pragma unroll
    for (int n = 0; n < TN; n += 4) {
        float4 c4 = FETCH_FLOAT4(C_block[OFFSET(ty + m, tx + n, N)]);
        c4.x = alpha * accum[m][n + 0] + beta * c4.x;
        c4.y = alpha * accum[m][n + 1] + beta * c4.y;
        c4.z = alpha * accum[m][n + 2] + beta * c4.z;
        c4.w = alpha * accum[m][n + 3] + beta * c4.w;
        FETCH_FLOAT4(C_block[OFFSET(ty + m, tx + n, N)]) = c4;
    }
}
```

åˆ†æä¸€ä¸‹æ€§èƒ½ï¼š

![matmul_v3](https://github.com/T4t4KAU/ai_infra_blogs/blob/main/cuda_programming/img/matmul_7.png)

å¯ä»¥çœ‹åˆ°æ‰§è¡Œæ—¶é—´åˆè¿›ä¸€æ­¥ç¼©çŸ­äº†ã€‚

## V4 åŒç¼“å†²æµæ°´çº¿

æºä»£ç ï¼š[matmul_v4.cu](https://github.com/T4t4KAU/ai_infra_blogs/blob/main/cuda_programming/src/matmul_v4.cu)

åœ¨è¿™ä¸ªç‰ˆæœ¬ä¸­ï¼Œå°†ç»§ç»­é’ˆå¯¹å†…å­˜è®¿é—®è¿›è¡Œä¼˜åŒ–ã€‚

åœ¨ä¸Šä¸€ä¸ªç‰ˆæœ¬ä¸­ï¼Œæˆ‘ä»¬æ¯è½®æ€»æ˜¯ï¼š

1. ä»å…¨å±€å†…å­˜ä¸­è¯»å–æ•°æ®åˆ°å…±äº«å†…å­˜
2. ä»å…±äº«å†…å­˜è¯»å–æ•°æ®è¿›è¡Œè®¡ç®—

å¯è§ï¼Œè¿™ä¸¤ä¸ªæ­¥éª¤éƒ½è¦ä½¿ç”¨å…±äº«å†…å­˜ï¼Œå› æ­¤è®¿å­˜å’Œè®¡ç®—åŸºæœ¬æ˜¯ä¸²è¡Œæ‰§è¡Œï¼ˆéš¾ä»¥é‡å ï¼‰ï¼Œæˆ‘ä»¬èƒ½ä¸èƒ½å°†è®¿å­˜å’Œè®¡ç®—é‡å ï¼Œè®©ä¸¤è€…å¹¶è¡Œæ‰§è¡Œï¼Ÿ

ç­”æ¡ˆæ˜¯æ˜¾ç„¶å¯ä»¥çš„ï¼Œæˆ‘ä»¬ä½¿ç”¨åŒç¼“å†²ç­–ç•¥å®ç°æ˜¾å­˜å—çš„äº¤æ›¿ä½¿ç”¨ï¼Œç”¨ä¸¤ä»½ç¼“å†²åŒºäº¤æ›¿å·¥ä½œï¼Œä¸€ä»½ç”¨äº"å½“å‰è®¡ç®—"ï¼Œå¦ä¸€ä»½æå‰"é¢„å–ä¸‹ä¸€æ‰¹æ•°æ®"ã€‚æ³¨æ„ï¼Œä¸æ˜¯åŒæ—¶ä½¿ç”¨ä¸¤å—å…±äº«å†…å­˜ï¼Œè€Œæ˜¯ä»»æ„æ—¶åˆ»ï¼Œæ¯ä¸ªçº¿ç¨‹åªåœ¨è¯»ä¸€å—å…±äº«å†…å­˜ï¼Œåªåœ¨å†™å¦ä¸€å—å…±äº«å†…å­˜ï¼Œæ²¡æœ‰"åŒä¸€æ•°æ®è¢«åŒæ—¶è¯»å†™"ã€‚

åŒç¼“å†²çš„ä½œç”¨æ˜¯è®©ã€ä¸‹ä¸€è½®æ‰€éœ€æ•°æ®çš„å‡†å¤‡ã€ä¸å¿…ç­‰ã€å½“å‰è½®çš„è®¡ç®—ã€ç»“æŸï¼Œé€šè¿‡ä¸¤ä»½äº’æ–¥ä½¿ç”¨çš„ç¼“å†²åŒºï¼ŒæŠŠå‡†å¤‡é˜¶æ®µå’Œè®¡ç®—é˜¶æ®µåœ¨æ—¶é—´ä¸Šé‡å èµ·æ¥ï¼Œä»è€Œéšè—å†…å­˜å’ŒåŒæ­¥å¸¦æ¥çš„å»¶è¿Ÿã€‚æœ¬è´¨ä¸Šæ˜¯ç”¨è®¡ç®—å»è¦†ç›–è®¿å­˜è¿™éƒ¨åˆ†æ—¶é—´ï¼Œå³éšè—è®¿é—®å»¶è¿Ÿã€‚

åƒè¿™æ ·å¼€è¾ŸåŒç¼“å†²åŒºï¼š

```c
/* ------------------------------
 * Shared double buffer for A and B tiles
 * ------------------------------ */
__shared__ float As[2][BK * BM];
__shared__ float Bs[2][BK * BN];
```

åŒæ—¶ï¼Œå¯„å­˜å™¨ä¹Ÿè¦ä½¿ç”¨åŒç¼“å†²ï¼š

```c
// register fragments
float a_frag[2][TM];
float b_frag[2][TN];
```

åœ¨æµæ°´çº¿çš„å¯åŠ¨çŠ¶æ€ï¼Œç°åœ¨å…ˆå°†Aå’ŒBçš„ç¬¬1ä¸ªTileæ”¾åˆ°å…±äº«å†…å­˜ä¸­ï¼Œå†ä»å…±äº«å†…å­˜ä¸­æ¬åˆ°å¯„å­˜å™¨ä¸­ï¼š

```c
#pragma unroll
    for (int i = 0; i < BM; i += a_tile_stride) {
        const int reg_idx = (i / a_tile_stride) * 4;
        FETCH_FLOAT4(ldg_a_reg[reg_idx]) = FETCH_FLOAT4(A_block[OFFSET(a_tile_row + i, a_tile_col, K)]);

        // store A into shared as transposed
        As[0][OFFSET(a_tile_col + 0, a_tile_row + i, BM)] = ldg_a_reg[reg_idx + 0];
        As[0][OFFSET(a_tile_col + 1, a_tile_row + i, BM)] = ldg_a_reg[reg_idx + 1];
        As[0][OFFSET(a_tile_col + 2, a_tile_row + i, BM)] = ldg_a_reg[reg_idx + 2];
        As[0][OFFSET(a_tile_col + 3, a_tile_row + i, BM)] = ldg_a_reg[reg_idx + 3];
    }
#pragma unroll
    for (int i = 0; i < BK; i += b_tile_stride) {
        FETCH_FLOAT4(Bs[0][OFFSET(b_tile_row + i, b_tile_col, BN)])
            = FETCH_FLOAT4(B_block[OFFSET(b_tile_row + i, b_tile_col, N)]);
    }

    __syncthreads();

    // preload frag for t=0 from shared buffer 0
#pragma unroll
    for (int m = 0; m < TM; m += 4) { FETCH_FLOAT4(a_frag[0][m]) = FETCH_FLOAT4(As[0][OFFSET(0, ty + m, BM)]); }
#pragma unroll
    for (int n = 0; n < TN; n += 4) { FETCH_FLOAT4(b_frag[0][n]) = FETCH_FLOAT4(Bs[0][OFFSET(0, tx + n, BN)]); }
```

è¿™æ˜¯ç¬¬ä¸€ä¸ªæ•°æ®åŠ è½½çš„æ­¥éª¤ï¼Œå…ˆå°†æ•°æ®ä»å…¨å±€å†…å­˜åŠ è½½åˆ°`As`å’Œ`Bs`çš„`buffer 0`ä¸­ï¼Œå†å°†æ•°æ®ä»`buffer 0`æ¬è¿åˆ°å¯„å­˜å™¨çš„`buffer 0`ä¸­ã€‚

æ¥ç€è¿›å…¥ä¸»å¾ªç¯æ‰§è¡Œæµæ°´çº¿ï¼Œåœ¨ä¸‹é¢çš„ä¸»å¾ªç¯ä¸­ï¼Œæ‰§è¡Œå¦‚ä¸‹æ­¥éª¤ï¼š

```c
while (è¿˜æœ‰ K-tile) {

    // (1) é¢„å–ä¸‹ä¸€tileï¼ˆglobal â†’ regï¼‰
    // å°†next tileæ”¾åˆ°å¯„å­˜å™¨ï¼Œç­‰åˆ°åˆé€‚çª—å£å†å†™å…¥ shared
    // é¿å…åœ¨ compute é˜¶æ®µç›´æ¥å†™ shared é€ æˆåŒæ­¥/äº‰ç”¨
    prefetch_next_tile_to_registers()

    // (2) è®¡ç®—å½“å‰ tile çš„å‰ BK-1 æ‹
    //     æ¯ä¸€æ‹ï¼šload(k+1) + compute(k)
    for k = 0 .. BK-2:
        preload_frag_from_shared(k+1) // (shared â†’ frag)
        compute_frag(k)
            
    // (3) æäº¤ä¸‹ä¸€tileï¼ˆreg â†’ sharedï¼‰å¹¶åŒæ­¥
    write_next_tile_to_shared()
    syncthreads()

    // (4) è®¡ç®—å½“å‰ tile çš„æœ€åä¸€æ‹
    compute_frag(BK-1)

    // åˆ‡æ¢ shared bufferï¼Œæ¨è¿› K
}
```

åœ¨V3ç‰ˆæœ¬çš„ä»£ç ä¸­ï¼Œæ¯æ¬¡ä»å…¨å±€å†…å­˜ä¸­è¯»å–Açš„æ•°æ®è¦åˆ†ä¸ºä¸¤æ­¥ï¼šä»å…¨å±€å†…å­˜æ¬åˆ°å¯„å­˜å™¨ï¼Œå†ä»å¯„å­˜å™¨æ¬åˆ°å…±äº«å†…å­˜ã€‚åœ¨ä¸Šè¿°çš„å¾ªç¯ä¸­ï¼Œæˆ‘ä»¬å…¶å®å°†è¿™ä¸¤æ­¥åˆ†ä¸ºäº†(1)å’Œ(3)ã€‚

å€¼çš„æ³¨æ„çš„æ˜¯ï¼Œ`Compute BK-1`è¢«å•ç‹¬æ‹¿å‡ºæ¥æ‰§è¡Œæ˜¯å› ä¸º`BK-1`å·²ç»æ˜¯æœ€åä¸€å—ï¼Œä¸å­˜åœ¨é¢„å–ä¸‹ä¸€å—ï¼Œæ‰€ä»¥è¿™ä¸€æ®µè¢«æ‹¿åˆ°æœ€åæ‰§è¡Œï¼Œæ­£å¥½æ‹¿æ¥è¦†ç›–å†…å­˜è®¿é—®ã€‚

åœ¨V3ä¸­ï¼Œæ¯è½®è¿­ä»£æ˜¯æŒ‰ç…§1-3-2-4çš„é¡ºåºè¿›è¡Œçš„ï¼Œç”±äºéƒ½è¦ä½¿ç”¨å…±äº«å†…å­˜ï¼Œæ‰€ä»¥è¿™4ä¸ªæ­¥éª¤åªèƒ½ä¸²è¡Œæ‰§è¡Œã€‚é‚£èƒ½ä¸èƒ½æŒ‰ç…§1-2-4-3çš„é¡ºåºæ‰§è¡Œï¼Ÿä¹Ÿæ˜¯å¯ä»¥çš„ï¼Œè¿™æ ·æµç¨‹å°±å˜æˆäº†ï¼š

```c
while (è¿˜æœ‰ K-tile) {

    // (1) é¢„å–ä¸‹ä¸€tileï¼ˆglobal â†’ regï¼‰
    prefetch_next_tile_to_registers()

    // (2) è®¡ç®—å½“å‰ tile çš„å‰ BK-1 æ‹
    //     æ¯ä¸€æ‹ï¼šload(k+1) + compute(k)
    for k = 0 .. BK-2:
        preload_frag_from_shared(k+1)
        compute_frag(k)

    // (4) è®¡ç®—å½“å‰ tile çš„æœ€åä¸€æ‹
    compute_frag(BK-1)
    
    // (3) æäº¤ä¸‹ä¸€tileï¼ˆreg â†’ sharedï¼‰å¹¶åŒæ­¥
    write_next_tile_to_shared()
    syncthreads()

    // åˆ‡æ¢ shared bufferï¼Œæ¨è¿› K
}
```

å¦‚æœè¿™æ ·çš„è¯ï¼Œæ‰§è¡Œæ—¶é—´ä¼šç¨å¾®å¢åŠ ï¼Œå› ä¸º`syncthreads()`æŒ‡ä»¤è¢«å»¶è¿Ÿï¼Œå³åŒæ­¥ç‚¹è¢«æ¨è¿Ÿï¼Œå¯¼è‡´ä¸‹ä¸€è½®å¯åŠ¨è¢«æ¨è¿Ÿã€‚

å¯ä»¥æ€»ç»“ï¼š

- (1)å’Œ(2)å¯ä»¥é‡å ï¼Œä¸äº‰ç”¨å…±äº«å†…å­˜
- (2)å†…éƒ¨çš„`preload_frag_from_shared(k+1)`å’Œ`compute_frag(k)`å¯ä»¥é‡å 
- (3)å’Œ(4)å¯ä»¥é‡å ï¼Œä¸äº‰ç”¨å…±äº«å†…å­˜
- (1)å’Œ(3)ä¸èƒ½é‡å ï¼Œå› ä¸ºè®¿é—®åŒä¸€æ‰¹å¯„å­˜å™¨

äºæ˜¯ï¼Œæ•´ä¸ªå¾ªç¯ä¸­æœ‰ä¸¤ä¸ªçº§åˆ«çš„æµæ°´çº¿ï¼š

- Tileçº§æµæ°´çº¿ï¼šå– next tile å’Œè®¡ç®— current tile å¯ä»¥é‡å 
- Fragmentçº§æµæ°´çº¿ï¼šåœ¨è®¡ç®— current tile ä¸­ï¼Œcompute å’Œ load å¯ä»¥é‡å 

å¦‚ä¸‹å†™å‡ºå®Œæ•´ä»£ç ï¼š

```c
// ---------------------------
// Main loop over K tiles
// ---------------------------
do {
    const int next_k = k_base + BK;

    // prefetch next tile from global into registers
    if (next_k < K) {
#pragma unroll
        for (int i = 0; i < BM; i += a_tile_stride) {
            int reg_idx = (i / a_tile_stride) * 4;

            FETCH_FLOAT4(ldg_a_reg[reg_idx])
                = FETCH_FLOAT4(A_block[OFFSET(a_tile_row + i, next_k + a_tile_col, K)]);
        }
#pragma unroll
        for (int i = 0; i < BK; i += b_tile_stride) {
            int reg_idx = (i / b_tile_stride) * 4;
            FETCH_FLOAT4(ldg_b_reg[reg_idx])
                = FETCH_FLOAT4(B_block[OFFSET(next_k + b_tile_row + i, b_tile_col, N)]);
        }
    }

    // shared buffer we are reading (current tile)
    // è¿™æ˜¯ä¸€ä¸ªçŠ¶æ€å˜é‡ï¼Œæ ‡è®°ä»å“ªå—Shared MemoryåŠ è½½æ•°æ®ï¼Œåœ¨ä¸‹ä¸€è½®ä¼šç¿»è½¬
    const int load_index = write_index ^ 1; 

#pragma unroll
    for (int t = 0; t < BK - 1; ++t) {
        // load next k-frag while computing current frag
#pragma unroll
        for (int m = 0; m < TM; m += 4) {
            FETCH_FLOAT4(a_frag[(t + 1) & 1][m]) = FETCH_FLOAT4(As[load_index][OFFSET(t + 1, ty + m, BM)]);
        }
#pragma unroll
        for (int n = 0; n < TN; n += 4) {
            FETCH_FLOAT4(b_frag[(t + 1) & 1][n]) = FETCH_FLOAT4(Bs[load_index][OFFSET(t + 1, tx + n, BN)]);
        }
#pragma unroll
        for (int i = 0; i < TM; ++i) {
#pragma unroll
            for (int j = 0; j < TN; ++j) { accum[i][j] += a_frag[t & 1][i] * b_frag[t & 1][j]; }
        }
    }

    if (next_k < K) {
#pragma unroll
        for (int i = 0; i < BM; i += a_tile_stride) {
            int reg_idx = (i / a_tile_stride) * 4;

            As[write_index][OFFSET(a_tile_col + 0, a_tile_row + i, BM)] = ldg_a_reg[reg_idx + 0];
            As[write_index][OFFSET(a_tile_col + 1, a_tile_row + i, BM)] = ldg_a_reg[reg_idx + 1];
            As[write_index][OFFSET(a_tile_col + 2, a_tile_row + i, BM)] = ldg_a_reg[reg_idx + 2];
            As[write_index][OFFSET(a_tile_col + 3, a_tile_row + i, BM)] = ldg_a_reg[reg_idx + 3];
        }
#pragma unroll
        for (int i = 0; i < BK; i += b_tile_stride) {
            int reg_idx = (i / b_tile_stride) * 4;

            FETCH_FLOAT4(Bs[write_index][OFFSET(b_tile_row + i, b_tile_col, BN)])
                = FETCH_FLOAT4(ldg_b_reg[reg_idx]);
        }

        __syncthreads();

        // preload frag for next tile's t=0
#pragma unroll
        for (int m = 0; m < TM; m += 4) {
            FETCH_FLOAT4(a_frag[0][m]) = FETCH_FLOAT4(As[write_index][OFFSET(0, ty + m, BM)]);
        }
#pragma unroll
        for (int n = 0; n < TN; n += 4) {
            FETCH_FLOAT4(b_frag[0][n]) = FETCH_FLOAT4(Bs[write_index][OFFSET(0, tx + n, BN)]);
        }

        write_index ^= 1; // ç¿»è½¬çŠ¶æ€ï¼Œåˆ‡æ¢ç¼“å†²åŒºï¼Œä½¿å¾—æ¯è½®äº¤æ›¿ä½¿ç”¨ç¼“å†²åŒº
    }
#pragma unroll
    for (int i = 0; i < TM; ++i) {
#pragma unroll
        for (int j = 0; j < TN; ++j) { accum[i][j] += a_frag[(BK - 1) & 1][i] * b_frag[(BK - 1) & 1][j]; }
    }

    k_base = next_k; // å‘å‰ç§»åŠ¨
} while (k_base < K);
```

å¦‚ä¸‹æ˜¯æ€§èƒ½åˆ†æç»“æœï¼Œå¯è§æ‰§è¡Œæ—¶é—´è¿›ä¸€æ­¥ç¼©çŸ­ï¼š

![matmul_v4](https://github.com/T4t4KAU/ai_infra_blogs/blob/main/cuda_programming/img/matmul_8.png)

## V5 Warp Tiling

æºä»£ç ï¼š[matmul_v5.cu](https://github.com/T4t4KAU/ai_infra_blogs/blob/main/cuda_programming/src/matmul_v5.cu)

åœ¨ä¸Šè¿°4ä¸ªç‰ˆæœ¬ä¸­ï¼Œéƒ½åªä½¿ç”¨äº†Block Tilingè¿›è¡Œä¼˜åŒ–ï¼Œä¹Ÿå°±æ˜¯ç”¨ä¸€ä¸ªçº¿ç¨‹å—å¤„ç†ä¸€ä¸ªçŸ©é˜µBlockï¼Œä½†äº‹å®ä¸Šï¼ŒGPUçš„æœ€å°è°ƒåº¦å•ä½æ˜¯warpï¼Œä½¿ç”¨Warp Tilingä¼˜åŒ–ï¼Œåœ¨æ›´ç»†ç²’åº¦ä¸‹æ§åˆ¶çº¿ç¨‹å¯¹å†…å­˜çš„è®¿é—®ï¼Œé¿å…Bank Conflictçš„å‘ç”Ÿã€‚å¦å¤–ï¼Œä¸€ä¸ªwarpä¸­çš„çº¿ç¨‹æ˜¯å¤©ç„¶åŒæ­¥çš„ï¼Œæ¯æ—¶æ¯åˆ»æ‰§è¡ŒåŒä¸€æ¡æŒ‡ä»¤ï¼Œä¸éœ€è¦ä»»ä½•æ˜¾å¼åŒæ­¥åŸè¯­ï¼Œä¹Ÿæ¶ˆé™¤å¤§é‡ä¸å¿…è¦çš„ `__syncthreads()`ï¼Œé™ä½äº†æ€§èƒ½å¼€é”€ã€‚

æˆ‘ä»¬å°†è¿ç»­çš„æ•°æ®èŒƒå›´åˆ†é…ç»™åŒä¸€ä¸ª warpï¼Œå¯ä»¥ä½¿ warp å†… 32 ä¸ªçº¿ç¨‹åœ¨æ‰§è¡ŒåŒä¸€æ¡å†…å­˜æŒ‡ä»¤æ—¶è®¿é—®åœ°å€å•è°ƒã€ç´§å‡‘ä¸”è¦†ç›–èŒƒå›´æœ€å°ï¼Œä»è€Œå‡å°‘å†…å­˜äº‹åŠ¡æ•°é‡å¹¶æé«˜ cache line çš„æœ‰æ•ˆåˆ©ç”¨ç‡ï¼›ç›¸æ¯”ä¹‹ä¸‹ï¼Œä»…åœ¨ block ç²’åº¦ä¿è¯æ•°æ®è¿ç»­å¹¶ä¸èƒ½ç¡®ä¿ warp å†…è®¿é—®æ¨¡å¼æ»¡è¶³è¿™äº›æ¡ä»¶ã€‚

ä¸€ä¸ªçº¿ç¨‹å—è¿˜æ˜¯ç®—ä¸€ä¸ªBM Ã— BNå¤§å°çš„å—ï¼Œä¸€ä¸ªwarpç®—å…¶ä¸­æ›´å°çš„WM Ã— WNå¤§å°çš„å—:

```c
// block tile coords on C
const int block_col = blockIdx.x; // along N
const int block_row = blockIdx.y; // along M

// warps in this block
const int warp_idx = threadIdx.x / WARP_SIZE;
const int lane = threadIdx.x % WARP_SIZE;

constexpr int WARPS_PER_COL = BN / WN;
constexpr int WARPS_PER_ROW = BM / WM;

// (warp_row, warp_col) within block tile
const int warp_col = warp_idx % WARPS_PER_COL;
const int warp_row = warp_idx / WARPS_PER_COL;
```

åŒæ—¶ï¼Œä¸€ä¸ªwarpè¿˜è¦åˆ‡åˆ†å‡ºæ›´å°çš„å—ï¼Œå› ä¸ºæ¯ä¸ª thread çš„å¯„å­˜å™¨èƒ½åŠ›æœ‰é™ï¼Œæ— æ³•ä¸€æ¬¡é“ºæ»¡ WMÃ—WNå¤§å°çš„å—ã€‚äºæ˜¯ä¸€ä¸ªwarp è´Ÿè´£çš„ WMÃ—WN å—å¹¶ä¸æ˜¯ä¸€æ¬¡æ€§ç®—å®Œï¼Œè€Œæ˜¯åˆ†å¤šæ¬¡ç®—ï¼š

```
for wsr in [0, WMITER)
  for wsc in [0, WNITER)
    è®¡ç®—ä¸€ä¸ª WSUBM Ã— WSUBN
```

warpå†…éƒ¨ç»†åˆ†ï¼š

```c
// Warp micro-tiling
// WMITER is derived: how many "sub-rows" we iterate in WM direction per warp step
// WSUBM/WSUBN define warp's internal subdivision
constexpr int WMITER = (WM * WN) / (WARP_SIZE * TM * TN * WNITER);
constexpr int WSUBM = WM / WMITER; // æ¯ä¸ªè¿­ä»£å¤„ç†çš„Mæ–¹å‘å­å—å¤§å°
constexpr int WSUBN = WN / WNITER; // æ¯ä¸ªè¿­ä»£å¤„ç†çš„Næ–¹å‘å­å—å¤§å°

// lane -> (thread_row_in_warp, thread_col_in_warp)
// warp covers WSUBM x WSUBN per (w_sub_row_idx, w_sub_col_idx) region,
// each thread computes TMxTN
constexpr int THREADS_PER_WSUBN = WSUBN / TN;

// warpå†…çº¿ç¨‹çš„äºŒç»´ä½ç½®
const int thread_col_in_warp = lane % THREADS_PER_WSUBN;
const int thread_row_in_warp = lane / THREADS_PER_WSUBN;
```

å‰©ä¸‹çš„è®¡ç®—é€»è¾‘å’Œä¸Šä¸€ç‰ˆæœ¬åŸºæœ¬ç±»ä¼¼ï¼Œåªä¸è¿‡å°†çŸ©é˜µâ€œåˆ‡çš„æ›´ç»†â€ã€‚

è¿™æ˜¯æˆ‘ä»¬æœ€ç»ˆçš„ä¼˜åŒ–ç‰ˆæœ¬ï¼Œæˆ‘ä»¬æ¥çœ‹çœ‹æ€§èƒ½æµ‹è¯•æŠ¥å‘Šï¼š

![matmul_v5](https://github.com/T4t4KAU/ai_infra_blogs/blob/main/cuda_programming/img/matmul_9.png)

å¯è§æ€§èƒ½åˆæœ‰äº†æ˜¾è‘—çš„æå‡ï¼Œå†ç”¨åŒæ ·çš„æµ‹è¯•æ–¹æ³•ï¼Œå’Œ[CUTLASS](https://github.com/NVIDIA/cutlass)è¿›è¡Œå¯¹æ¯”ï¼Œå¦‚ä¸‹æ˜¯ä¸€æ®µæµ‹è¯•ä»£ç ï¼š

```c
#include <cstdio>
#include <cstdlib>
#include <cuda_runtime.h>
#include <iostream>

#include "cutlass/cutlass.h"
#include "cutlass/gemm/device/gemm.h"
#include "cutlass/layout/matrix.h"
#include "cutlass/epilogue/thread/linear_combination.h"

#define CHECK_CUDA_ERROR(call)                                                                 \
    do {                                                                                       \
        cudaError_t err = call;                                                                \
        if (err != cudaSuccess) {                                                              \
            fprintf(stderr, "CUDA error %s:%d: %s\n",                                          \
                    __FILE__, __LINE__, cudaGetErrorString(err));                               \
            exit(EXIT_FAILURE);                                                                \
        }                                                                                      \
    } while (0)

#define CEIL_DIV(x, y) (((x) + (y)-1) / (y))

int main() {
    /* =============================
     * Matrix size
     * ============================= */
    const int M = 4096;
    const int N = 4096;
    const int K = 4096;

    const float alpha = 1.0f;
    const float beta  = 0.0f;

    size_t bytes_A = size_t(M) * K * sizeof(float);
    size_t bytes_B = size_t(K) * N * sizeof(float);
    size_t bytes_C = size_t(M) * N * sizeof(float);

    /* =============================
     * Host allocation & init
     * ============================= */
    float *h_A = (float*)malloc(bytes_A);
    float *h_B = (float*)malloc(bytes_B);
    float *h_C = (float*)malloc(bytes_C);

    for (int i = 0; i < M * K; ++i) h_A[i] = 1.0f;
    for (int i = 0; i < K * N; ++i) h_B[i] = 2.0f;
    for (int i = 0; i < M * N; ++i) h_C[i] = 0.0f;

    /* =============================
     * Device allocation
     * ============================= */
    float *d_A, *d_B, *d_C;
    CHECK_CUDA_ERROR(cudaMalloc(&d_A, bytes_A));
    CHECK_CUDA_ERROR(cudaMalloc(&d_B, bytes_B));
    CHECK_CUDA_ERROR(cudaMalloc(&d_C, bytes_C));

    CHECK_CUDA_ERROR(cudaMemcpy(d_A, h_A, bytes_A, cudaMemcpyHostToDevice));
    CHECK_CUDA_ERROR(cudaMemcpy(d_B, h_B, bytes_B, cudaMemcpyHostToDevice));
    CHECK_CUDA_ERROR(cudaMemcpy(d_C, h_C, bytes_C, cudaMemcpyHostToDevice));

    /* =============================
     * CUTLASS GEMM å®šä¹‰ï¼ˆSIMTï¼‰
     * ============================= */
    using ElementA = float;
    using ElementB = float;
    using ElementC = float;
    using ElementAccumulator = float;

    using LayoutA = cutlass::layout::RowMajor;
    using LayoutB = cutlass::layout::RowMajor;
    using LayoutC = cutlass::layout::RowMajor;

    using Gemm = cutlass::gemm::device::Gemm<
        ElementA, LayoutA,
        ElementB, LayoutB,
        ElementC, LayoutC,
        ElementAccumulator,
        cutlass::arch::OpClassSimt,        
        cutlass::arch::Sm120,               
        cutlass::gemm::GemmShape<128,128,8>,   // Threadblock tile
        cutlass::gemm::GemmShape<64,64,8>,     // Warp tile
        cutlass::gemm::GemmShape<1,1,1>,       // Instruction tile (SIMT)
        cutlass::epilogue::thread::LinearCombination<
            ElementC, 1, ElementAccumulator, ElementAccumulator>,
        cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
        2   
    >;

    Gemm gemm_op;

    cutlass::gemm::GemmCoord problem_size(M, N, K);

    typename Gemm::Arguments args(
        problem_size,
        {d_A, K},
        {d_B, N},
        {d_C, N},
        {d_C, N},
        {alpha, beta}
    );

    /* =============================
     * Warmup
     * ============================= */
    const int warmup_iters = 10;
    for (int i = 0; i < warmup_iters; ++i) {
        cutlass::Status status = gemm_op(args);
        if (status != cutlass::Status::kSuccess) {
            std::cerr << "CUTLASS GEMM failed\n";
            return -1;
        }
    }
    CHECK_CUDA_ERROR(cudaDeviceSynchronize());

    /* =============================
     * Timed run
     * ============================= */
    const int repeat_iters = 10;

    cudaEvent_t start, stop;
    CHECK_CUDA_ERROR(cudaEventCreate(&start));
    CHECK_CUDA_ERROR(cudaEventCreate(&stop));

    CHECK_CUDA_ERROR(cudaEventRecord(start));
    for (int i = 0; i < repeat_iters; ++i) {
        cutlass::Status status = gemm_op(args);
        if (status != cutlass::Status::kSuccess) {
            std::cerr << "CUTLASS GEMM failed\n";
            return -1;
        }
    }
    CHECK_CUDA_ERROR(cudaEventRecord(stop));
    CHECK_CUDA_ERROR(cudaEventSynchronize(stop));

    float elapsed_ms = 0.0f;
    CHECK_CUDA_ERROR(cudaEventElapsedTime(&elapsed_ms, start, stop));

    float avg_ms = elapsed_ms / repeat_iters;

    /* =============================
     * GFLOPS
     * ============================= */
    double flops = 2.0 * double(M) * N * K;
    double gflops = flops / (avg_ms * 1e6);

    printf("CUTLASS SGEMM (SIMT FP32):\n");
    printf("  Avg time: %.3f ms\n", avg_ms);
    printf("  Perf:     %.2f GFLOPS\n", gflops);

    /* =============================
     * Cleanup
     * ============================= */
    cudaEventDestroy(start);
    cudaEventDestroy(stop);

    free(h_A);
    free(h_B);
    free(h_C);

    cudaFree(d_A);
    cudaFree(d_B);
    cudaFree(d_C);

    cudaDeviceReset();
    return 0;
}
```

ç¼–è¯‘å‘½ä»¤ï¼š

```c
nvcc -O3 -std=c++17 \
  -I$CUTLASS/include \
  -I$CUTLASS/tools/util/include \
  cutlass_sgemm_bench.cu \
  -o cutlass_sgemm_bench
```

æŸ¥çœ‹æ€§èƒ½æµ‹è¯•æŠ¥å‘Šï¼š

![matmul_v5](https://github.com/T4t4KAU/ai_infra_blogs/blob/main/cuda_programming/img/matmul_10.png)

å¯ä»¥å‘ç°æˆ‘ä»¬çš„æ‰‹å†™kernelåœ¨è¿™æ ·çš„æµ‹è¯•ç¯å¢ƒä¸‹çš„æ€§èƒ½å·²ç»éå¸¸æ¥è¿‘CUTLASSäº†ğŸ˜

## è¡¥å……ä¸æ€»ç»“

æœ¬æ–‡é€šè¿‡ **V1 â†’ V5** äº”ä¸ªç‰ˆæœ¬ï¼Œé€æ­¥æ‰‹å†™å®ç°å¹¶ä¼˜åŒ–ä¸€ä¸ª **CUDA SGEMMï¼ˆFP32 çŸ©é˜µä¹˜æ³•ï¼‰Kernel**ï¼Œç›®æ ‡æ˜¯ï¼š

- å‡å°‘å…¨å±€å†…å­˜è®¿é—®
- æé«˜æ•°æ®å¤ç”¨
- æå‡è®¡ç®—å¼ºåº¦ï¼ˆCompute / Memory Ratioï¼‰
- éšè—è®¿å­˜ä¸åŒæ­¥å»¶è¿Ÿ
- æœ€ç»ˆæ€§èƒ½é€¼è¿‘ **CUTLASSï¼ˆSIMT è·¯å¾„ï¼‰**

å¯åšå¦‚ä¸‹æ€»ç»“ï¼š

| ç‰ˆæœ¬                           | æ ¸å¿ƒæ€æƒ³                      | ä¸»è¦åšæ³•                                                     | ä¼˜ç‚¹                                                         | ä¸»è¦é—®é¢˜æˆ–å±€é™                                               | æ•ˆæœä¸ç»“è®º                                      |
| ------------------------------ | ----------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ----------------------------------------------- |
| V1 æœ€æœ´ç´ å®ç°ï¼ˆBaselineï¼‰      | ä¸€çº¿ç¨‹ä¸€å…ƒç´                   | æ¯ä¸ªçº¿ç¨‹è®¡ç®—ä¸€ä¸ª C[m,n] å…ƒç´ ï¼›ä»å…¨å±€å†…å­˜è¯»å– A çš„ä¸€æ•´è¡Œä¸ B çš„ä¸€æ•´åˆ—ï¼›åœ¨å¯„å­˜å™¨ä¸­å®Œæˆç´¯åŠ  | å®ç°æ–¹å¼ç›´è§‚ç®€å•ï¼›ä¾¿äºç†è§£ CUDA çº¿ç¨‹ä¸ç½‘æ ¼æ¨¡å‹               | å…¨å±€å†…å­˜è®¿é—®æå…¶é¢‘ç¹ï¼›å‡ ä¹æ²¡æœ‰æ•°æ®å¤ç”¨ï¼›è®¡ç®—å¼ºåº¦æä½ï¼›L1 Cache è®¿é—®å‹åŠ›å·¨å¤§ | æ€§èƒ½å®Œå…¨å—é™äºå†…å­˜å¸¦å®½ï¼Œä»…èƒ½ä½œä¸ºæ­£ç¡®æ€§éªŒè¯      |
| V2 Thread Tile + Shared Memory | Block ä¸ Thread åˆ†å—          | ä¸€ä¸ªçº¿ç¨‹å—è®¡ç®—ä¸€ä¸ª BMÃ—BN çš„ C Blockï¼›K ç»´æŒ‰ BK åˆ‡åˆ†ï¼›æ¯ä¸ªçº¿ç¨‹è®¡ç®— TMÃ—TN å­å— | å¼•å…¥å…±äº«å†…å­˜ï¼›çº¿ç¨‹å—å†…å®ç°æ•°æ®å¤ç”¨ï¼›æ˜¾è‘—å‡å°‘å…¨å±€å†…å­˜è®¿é—®ï¼›æé«˜å¯„å­˜å™¨çº§è®¡ç®—å¯†åº¦ | å‚æ•°é€‰æ‹©å¤æ‚ï¼›ç´¢å¼•è®¡ç®—ä¸çº¿ç¨‹æ˜ å°„éš¾åº¦è¾ƒé«˜                     | æ‰§è¡Œæ—¶é—´æ˜æ˜¾ä¸‹é™ï¼Œè®¡ç®—å¯†åº¦å’Œç¼“å­˜åˆ©ç”¨ç‡æ˜¾è‘—æå‡  |
| V3 å‘é‡åŒ–è®¿å­˜                  | åˆå¹¶è®¿å­˜ä¸ Bank Conflict è§„é¿ | ä½¿ç”¨ float4 è¿›è¡Œå‘é‡åŒ–åŠ è½½ä¸å­˜å‚¨ï¼›A Tile åœ¨å…±äº«å†…å­˜ä¸­ä»¥è½¬ç½®å½¢å¼å­˜æ”¾ | å‡å°‘è®¿å­˜æŒ‡ä»¤æ•°é‡ï¼›æé«˜å†…å­˜äº‹åŠ¡åˆ©ç”¨ç‡ï¼›æœ‰æ•ˆé™ä½å…±äº«å†…å­˜ Bank Conflict | å¯¹æ•°æ®å¯¹é½ä¸è¾¹ç•Œæ¡ä»¶è¦æ±‚æ›´ä¸¥æ ¼                               | å†…å­˜ååè¿›ä¸€æ­¥æå‡ï¼ŒKernel æ‰§è¡Œæ—¶é—´ç»§ç»­ç¼©çŸ­     |
| V4 åŒç¼“å†²æµæ°´çº¿                | å»¶è¿Ÿéšè—ï¼ˆLatency Hidingï¼‰    | ä½¿ç”¨ä¸¤å¥—å…±äº«å†…å­˜ç¼“å†²åŒºäº¤æ›¿å·¥ä½œï¼›é¢„å–ä¸‹ä¸€ Tile çš„åŒæ—¶è®¡ç®—å½“å‰ Tileï¼›æ„å»º Tile çº§ä¸ Fragment çº§æµæ°´çº¿ | å®ç°è®¿å­˜ä¸è®¡ç®—é‡å ï¼›æœ‰æ•ˆéšè—å…¨å±€å†…å­˜ä¸åŒæ­¥å»¶è¿Ÿ               | ä»£ç ç»“æ„å¤æ‚åº¦æ˜¾è‘—æå‡ï¼Œå¯è¯»æ€§ä¸ç»´æŠ¤æˆæœ¬å¢åŠ                  | æ‰§è¡Œæ—¶é—´è¿›ä¸€æ­¥ä¸‹é™ï¼ŒSM åˆ©ç”¨ç‡æ˜æ˜¾æé«˜           |
| V5 Warp Tilingï¼ˆæœ€ç»ˆå½¢æ€ï¼‰     | ä»¥ Warp ä¸ºåŸºæœ¬è®¡ç®—å•å…ƒ        | å°† Block Tile ç»†åŒ–ä¸º Warp Tileï¼›æ¯ä¸ª Warp è´Ÿè´£ WMÃ—WN å­å—ï¼›Warp å†…è¿›è¡Œ micro-tiling | Warp å†…å¤©ç„¶åŒæ­¥ï¼›æ˜¾è‘—å‡å°‘åŒæ­¥å¼€é”€ï¼›å†…å­˜è®¿é—®æ¨¡å¼æ›´åŠ è§„æ•´ï¼›å‡ ä¹æ¶ˆé™¤ Warp å†… Bank Conflict | å®ç°éš¾åº¦é«˜ï¼›å‚æ•°è®¾è®¡ä¸è°ƒä¼˜å¤æ‚                               | æ€§èƒ½æ¥è¿‘ CUTLASS çš„ SIMT å®ç°ï¼Œè¾¾åˆ°å‡†å·¥ä¸šçº§æ°´å¹³ |
